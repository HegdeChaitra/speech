{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import string\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "df_r = pd.read_csv(\"./raw_data/hollow_train.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>SUPPORT COMPREHENSIVE SUPPORT Investment Accou...</td>\n",
       "      <td>2018-09-28 04:37:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\"\"Property investment management software bui...</td>\n",
       "      <td>2018-09-28 04:37:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Of late we have seen some tentative steps take...</td>\n",
       "      <td>2018-09-28 04:36:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Create a Rental Property Analysis at Your Fing...</td>\n",
       "      <td>2018-09-28 04:34:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Guide to Personal Investment Software The sele...</td>\n",
       "      <td>2018-09-28 04:38:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1                                                  2  \\\n",
       "0  18  1  SUPPORT COMPREHENSIVE SUPPORT Investment Accou...   \n",
       "1  18  1  \"\"\"Property investment management software bui...   \n",
       "2  18  1  Of late we have seen some tentative steps take...   \n",
       "3  18  1  Create a Rental Property Analysis at Your Fing...   \n",
       "4  18  1  Guide to Personal Investment Software The sele...   \n",
       "\n",
       "                     3  \n",
       "0  2018-09-28 04:37:13  \n",
       "1  2018-09-28 04:37:26  \n",
       "2  2018-09-28 04:36:33  \n",
       "3  2018-09-28 04:34:46  \n",
       "4  2018-09-28 04:38:59  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels between 0 to n_class-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5842\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"extracted_content\",\"topic_id\"])\n",
    "df['extracted_content'] = df_r[2]\n",
    "df['topic_id'] = df_r[1]\n",
    "label_encoder = list(np.unique(np.array(df_r[1])))\n",
    "pickle.dump(label_encoder,open(\"./raw_data/hollow_label_encoder\",'wb'))\n",
    "l = len(label_encoder)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(df):\n",
    "    df['extracted_content'] = df['extracted_content'].apply(lambda x: \" \".join(x.lower() for x in x.split() if x not in punct))\n",
    "    df['topic_id'] = df['topic_id'].apply(lambda x: label_encoder.index(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_content</th>\n",
       "      <th>topic_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>support comprehensive support investment accou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\"\"property investment management software bui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of late we have seen some tentative steps take...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>create a rental property analysis at your fing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guide to personal investment software the sele...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   extracted_content  topic_id\n",
       "0  support comprehensive support investment accou...         0\n",
       "1  \"\"\"property investment management software bui...         0\n",
       "2  of late we have seen some tentative steps take...         0\n",
       "3  create a rental property analysis at your fing...         0\n",
       "4  guide to personal investment software the sele...         0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset as train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "df_train = pd.DataFrame(columns=['extracted_content','topic_id'])\n",
    "df_val = pd.DataFrame(columns=['extracted_content','topic_id'])\n",
    "for train_index, test_index in sss.split(df['extracted_content'], df['topic_id']):\n",
    "    df_train = df.iloc[train_index]\n",
    "    df_val = df.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        extracted_content  topic_id\n",
       " 291418  according to a new market intelligence report ...      5423\n",
       " 249896  alstom is a player in substation automations s...      4636\n",
       " 191857  fedex supports young entrepreneurship a team o...      3564\n",
       " 3355    material handling from logistics centers to wa...        61\n",
       " 164672  \"\"\"it is known as china’s silicon valley and i...      3061,\n",
       " (235150, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(),df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        extracted_content  topic_id\n",
       " 289270  gilat’s skyedge ii-c uses hts resources to del...      5382\n",
       " 66747   this new initiative takes advantage of the gro...      1231\n",
       " 297123  the 7 simple rules of using a clarisonic clean...      5531\n",
       " 234384  as any business owner or senior hr executive w...      4339\n",
       " 37563   business consulting services the business cons...       693,\n",
       " (78384, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head(),df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./processed_data/df_train.csv\",index=False)\n",
    "df_val.to_csv(\"./processed_data/df_val.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call define_process_hollow.py for further processing - mapping tokens to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python define_process_hollow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_attention.py [-h] [--max_len MAX_LEN] [--bs BS]\r\n",
      "                          [--n_vocab N_VOCAB] [--lr LR] [--n_epoch N_EPOCH]\r\n",
      "                          [--do_train] [--do_eval] [--source_path SOURCE_PATH]\r\n",
      "                          [--train_data TRAIN_DATA] [--val_data VAL_DATA]\r\n",
      "                          [--token_id TOKEN_ID] [--emb_dim EMB_DIM]\r\n",
      "                          [--save_path SAVE_PATH] [--model_load MODEL_LOAD]\r\n",
      "                          --model_save MODEL_SAVE\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --max_len MAX_LEN     Maximum length of the sentence. default=500\r\n",
      "  --bs BS               Batch size. default=32\r\n",
      "  --n_vocab N_VOCAB     Vocabulary size. default=50000\r\n",
      "  --lr LR               Learning rate. default=5e-4\r\n",
      "  --n_epoch N_EPOCH     Number of epochs. default=30\r\n",
      "  --do_train            Whether to run training. default=False\r\n",
      "  --do_eval             Whether to run eval on the dev set. default=False\r\n",
      "  --source_path SOURCE_PATH\r\n",
      "                        Path to dataset. default=./processed_data/\r\n",
      "  --train_data TRAIN_DATA\r\n",
      "                        Name of train dataset. default=idized_hollow_train.csv\r\n",
      "  --val_data VAL_DATA   Name of val dataset. default=idized_hollow_val.csv\r\n",
      "  --token_id TOKEN_ID   Name of token&id pickle file. default=token_and_id.pk\r\n",
      "  --emb_dim EMB_DIM     embedding dimension. default=200\r\n",
      "  --save_path SAVE_PATH\r\n",
      "                        Directory where models are to be saved\r\n",
      "  --model_load MODEL_LOAD\r\n",
      "                        Complete path to the Model to load for continued\r\n",
      "                        training/ evaluation. default=None\r\n",
      "  --model_save MODEL_SAVE\r\n",
      "                        Name of the model to be saved. required=True\r\n"
     ]
    }
   ],
   "source": [
    "!python train_attention.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "number of classes 5842\n",
      "model loaded\n",
      "/home/chegde/anaconda3/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'def_attn_model_word_eff.Attention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "training begun\n",
      "Attention(\n",
      "  (embedding): Embedding(50002, 200, padding_idx=0)\n",
      "  (gru): GRU(200, 50, batch_first=True, bidirectional=True)\n",
      "  (sm): Softmax()\n",
      "  (lin_bias): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dp): Dropout(p=0.6)\n",
      "  (linear1): Linear(in_features=100, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (linear_out): Linear(in_features=1000, out_features=5842, bias=True)\n",
      ")\n",
      "/home/chegde/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "time taken= 106.20869135856628\n",
      "top1_acc 69.29092671973872\n",
      "top5_acc 83.40732802612779\n",
      "top10_acc 86.71284956113493\n"
     ]
    }
   ],
   "source": [
    "!python train_attention.py --do_eval --model_load \"model_att5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "number of classes 5842\n",
      "model defined\n",
      "training begun\n",
      "Attention(\n",
      "  (embedding): Embedding(50002, 200, padding_idx=0)\n",
      "  (gru): GRU(200, 50, batch_first=True, bidirectional=True)\n",
      "  (sm): Softmax()\n",
      "  (lin_bias): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (dp): Dropout(p=0.6)\n",
      "  (linear1): Linear(in_features=100, out_features=500, bias=True)\n",
      "  (linear2): Linear(in_features=500, out_features=1000, bias=True)\n",
      "  (linear_out): Linear(in_features=1000, out_features=5842, bias=True)\n",
      ")\n",
      "/home/chegde/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "epoch 0 train loss = 8.213029274247997, accurancy = 0.004167552625983415 time = 468.70602774620056\n",
      "epoch 0 validate loss = 6.638071433552238, accurancy = 0.05270208205756277 time = 104.84463810920715\n",
      "epoch 1 train loss = 5.933590058394247, accurancy = 0.08071018498830533 time = 503.0820233821869\n",
      "epoch 1 validate loss = 4.1879187500411135, accurancy = 0.3160849152888345 time = 108.19427800178528\n",
      "Training completed. Best accuracy is 0.3160849152888345\n"
     ]
    }
   ],
   "source": [
    "!python train_attention.py --do_train --model_save \"sample\" --n_epoch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
